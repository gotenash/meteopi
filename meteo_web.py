#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import csv
import time
import base64
from datetime import datetime, timedelta
from flask import Flask, render_template, send_file, make_response, redirect, url_for, jsonify, request, flash
from flask_login import LoginManager, UserMixin, login_user, logout_user, login_required, current_user
import pandas as pd
import os
import matplotlib.pyplot as plt
import shutil
import matplotlib.font_manager as fm
import matplotlib
import matplotlib.dates as mdates # Ajout pour le formatage des dates sur l'axe X
import io
import re # Ajout du module pour les expressions r√©guli√®res
import numpy as np # Ajout de numpy pour les calculs
from werkzeug.security import generate_password_hash, check_password_hash
import requests # Ajout pour les requ√™tes API externes
import json # Ajout pour g√©rer le fichier de configuration

# On d√©sactive l'affichage de Matplotlib sur le serveur
plt.switch_backend('Agg')

def cleanup_csv_on_startup(filepath):
    """
    V√©rifie et nettoie le fichier CSV au d√©marrage.
    Tente de r√©parer les lignes corrompues (contenant des caract√®res NUL)
    de mani√®re plus performante et robuste.
    """
    if not os.path.exists(filepath):
        return
    
    # Expression r√©guli√®re pour trouver un timestamp valide (ex: 2025-11-08 10:30:00)
    # C'est beaucoup plus robuste que de chercher seulement l'ann√©e.
    timestamp_regex = re.compile(r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}')
    
    try:
        # On lit le fichier en mode binaire pour d√©tecter les NUL bytes
        with open(filepath, 'rb') as f:
            content = f.read()

        # On ne proc√®de √† la r√©√©criture que si des caract√®res corrompus sont trouv√©s
        if b'\x00' not in content:
            print(f"Le fichier '{filepath}' est propre. Aucun nettoyage n√©cessaire.")
            return

        print(f"Corruption d√©tect√©e dans '{filepath}'. D√©but du nettoyage...")
        cleaned_lines = []
        # On d√©code en ignorant les erreurs pour pouvoir it√©rer sur les lignes
        for line in content.decode('utf-8', errors='ignore').splitlines():
            # On cherche une date valide dans la ligne pour la r√©cup√©rer
            match = timestamp_regex.search(line)
            if match:
                # On r√©cup√®re la partie valide de la ligne √† partir de la date
                recovered_line = line[match.start():]
                cleaned_lines.append(recovered_line)
            else:
                print(f"Ligne corrompue irr√©cup√©rable ignor√©e : {line.strip()}")

        # On r√©√©crit le fichier original avec les lignes nettoy√©es
        with open(filepath, 'w', newline='', encoding='utf-8') as f:
            f.write('\n'.join(cleaned_lines) + '\n')
        print(f"Le fichier '{filepath}' a √©t√© nettoy√© avec succ√®s.")
    except Exception as e:
        print(f"Erreur critique lors du nettoyage du fichier CSV : {e}")

CONFIG_FILE = "config.json"

def load_config():
    """Charge la configuration depuis config.json."""
    try:
        with open(CONFIG_FILE, 'r') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        # Si le fichier n'existe pas ou est corrompu, on cr√©e une config par d√©faut
        default_config = {
            "owm_api_key": "METTRE_VOTRE_CLE_ICI",
            "latitude": 48.85, # Paris par d√©faut
            "longitude": 2.35
        }
        save_config(default_config)
        return default_config

def save_config(config_data):
    """Sauvegarde la configuration dans config.json."""
    with open(CONFIG_FILE, 'w') as f:
        json.dump(config_data, f, indent=4)

# --- Chargement de la configuration au d√©marrage ---
config = load_config()

app = Flask(__name__)
# Cl√© secr√®te pour la gestion des sessions Flask (n√©cessaire pour le login)

# On ex√©cute le nettoyage du CSV au d√©marrage de l'application
cleanup_csv_on_startup("meteo_log.csv")

# Changez cette cl√© pour une cha√Æne de caract√®res al√©atoire !
app.secret_key = 'une-cle-secrete-tres-difficile-a-deviner'

# --- Configuration de Flask-Login ---
login_manager = LoginManager()
login_manager.init_app(app)
login_manager.login_view = 'login' # Redirige les utilisateurs non connect√©s vers la page /login
login_manager.login_message = "Veuillez vous connecter pour acc√©der √† cette page."
login_manager.login_message_category = "info"

# --- Mod√®le Utilisateur simple ---
class User(UserMixin):
    def __init__(self, id, username, password=None, password_hash=None):
        self.id = id
        self.username = username
        if password:
            self.password_hash = generate_password_hash(password)
        elif password_hash:
            self.password_hash = password_hash
        else:
            self.password_hash = generate_password_hash("password")

    def check_password(self, password):
        return check_password_hash(self.password_hash, password)

CSV_FILE = "meteo_log.csv"
PLUVIOMETER_EVENT_LOG = "pluviometer_events.log" # Chemin vers le fichier de log des √©v√©nements du pluviom√®tre
# Calibration du pluviom√®tre (identique √† meteo_capteur.py) - 2024-05-26 (exp√©rimentale)
# Bas√© sur le test : 100ml d'eau (10mm) pour 53 basculements.
MM_PER_TIP = 0.213 # Correction pour correspondre au capteur

# --- Base de donn√©es utilisateur ---
# On r√©cup√®re le hash depuis la config pour la persistance, sinon d√©faut "password"
admin_hash = config.get('admin_password_hash')
if not admin_hash:
    admin_hash = generate_password_hash("password")

users = {
    "1": User(id="1", username="admin", password_hash=admin_hash)
}

# On utilise maintenant les valeurs du fichier de configuration
OWM_API_KEY = config.get("owm_api_key")
LATITUDE = config.get("latitude")
LONGITUDE = config.get("longitude")

def generate_hourly_graph_base64(input_df, filter_recent=True, title="Donn√©es m√©t√©o agr√©g√©es par heure (48 derni√®res heures)"):
    """G√©n√®re un graphique horaire √† partir du DataFrame et le retourne en base64."""
    if input_df.empty:
        return None

    df = input_df.copy()
    if filter_recent:
        # Filtrer les donn√©es des derni√®res 48 heures
        forty_eight_hours_ago = datetime.now() - timedelta(hours=48)
        df = df[df['time'] > forty_eight_hours_ago]

    df.set_index('time', inplace=True)

    # Agr√©ger les donn√©es par heure
    # Moyenne pour la temp√©rature et l'humidit√©, somme pour la pluie
    df_hourly = df.resample('H').agg({'temp': 'mean', 'hum': 'mean', 'rain': 'sum'})
    df_hourly.dropna(subset=['temp', 'hum'], how='all', inplace=True) # Supprimer les heures sans donn√©es

    if df_hourly.empty:
        return None

    fig, ax1 = plt.subplots(figsize=(12, 6))

    ax1.set_xlabel("Heure")
    ax1.set_ylabel("Temp (¬∞C) / Humidit√© (%)")
    # Utilisation de l'index datetime directement pour l'axe X
    ax1.plot(df_hourly.index, df_hourly["temp"], marker="o", color="tab:red", label="Temp√©rature (¬∞C)")
    ax1.plot(df_hourly.index, df_hourly["hum"], marker="o", color="tab:blue", label="Humidit√© (%)")
    ax1.grid(True, linestyle='--', alpha=0.6)

    # Formatage de l'axe X pour afficher uniquement l'heure et g√©rer l'espacement
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Hh'))
    # D√©finir les localisateurs pour les ticks majeurs (toutes les 3 heures) et mineurs (toutes les heures)
    # Cela aide √† √©viter la superposition des labels et √† avoir une bonne granularit√©
    ax1.xaxis.set_major_locator(mdates.HourLocator(interval=3))
    ax1.xaxis.set_minor_locator(mdates.HourLocator(interval=1))

    # Axe Y de droite pour la Pluie
    ax2 = ax1.twinx()
    ax2.set_ylabel("Pluie (mm)", color="tab:green")
    # Utilisation de l'index datetime directement pour l'axe X
    # On sp√©cifie la largeur des barres √† 1/24 d'une journ√©e (soit 1 heure) pour un affichage pr√©cis.
    # L'alignement 'edge' place la barre √† droite de son point de donn√©es, ce qui est plus intuitif pour une somme horaire.
    ax2.bar(df_hourly.index, df_hourly["rain"], width=1/24, color="tab:green", alpha=0.6, label="Pluie (mm)", align='edge')
    ax2.tick_params(axis='y', labelcolor="tab:green")

    fig.legend(loc="upper left", bbox_to_anchor=(0.1, 0.9))
    plt.xticks(rotation=70, ha="right")
    plt.title(title)
    plt.tight_layout()

    return _save_graph_to_base64(fig)

def get_weather_prediction(df):
    """Analyse la tendance de la pression pour fournir une pr√©diction simple."""
    # V√©rifie si la colonne 'pressure' existe et contient des donn√©es valides
    if 'pressure' not in df.columns or df['pressure'].isnull().all():
        return None # Pas de pr√©diction si pas de donn√©es de pression

    # On ne garde que les lignes avec des donn√©es de pression valides
    df_pressure = df.dropna(subset=['pressure'])

    if len(df_pressure) < 4:
        return "Donn√©es insuffisantes pour une pr√©diction."

    # On regarde les 3 derni√®res heures
    three_hours_ago = datetime.now() - timedelta(hours=3)
    recent_data = df_pressure[df_pressure['time'] > three_hours_ago]

    if len(recent_data) < 2:
        return "Donn√©es insuffisantes pour une pr√©diction."

    # Calcul de la tendance de pression (hPa par 3 heures)
    pressure_change = recent_data['pressure'].iloc[-1] - recent_data['pressure'].iloc[0]

    # Logique de pr√©diction
    if pressure_change < -1.6:
        return "D√©t√©rioration rapide, pluie ou vent probable."
    elif pressure_change < -0.5:
        return "Lente d√©gradation, temps devenant nuageux."
    elif pressure_change > 1.6:
        return "Am√©lioration rapide, temps s'√©claircissant."
    elif pressure_change > 0.5:
        return "Lente am√©lioration, temps stable."
    else:
        current_pressure = recent_data['pressure'].iloc[-1]
        if current_pressure > 1022:
            return "Temps stable et calme (haute pression)."
        elif current_pressure < 1000:
            return "Temps instable et maussade (basse pression)."
        else:
            return "Pas de changement significatif pr√©vu."

def generate_wind_rose_base64(df):
    """G√©n√®re une rose des vents et la retourne en base64."""
    df_wind = df.dropna(subset=['wind_dir_str'])
    if df_wind.empty:
        return None

    # Ordre cardinal et conversion en radians
    directions_map = {
        'N': 0, 'NE': np.pi/4, 'E': np.pi/2, 'SE': 3*np.pi/4,
        'S': np.pi, 'SO': 5*np.pi/4, 'O': 3*np.pi/2, 'NO': 7*np.pi/4
    }
    dir_order = ['N', 'NE', 'E', 'SE', 'S', 'SO', 'O', 'NO']
    
    # Calcul de la fr√©quence de chaque direction
    counts = df_wind['wind_dir_str'].value_counts()
    # S'assure que toutes les directions sont pr√©sentes, m√™me avec une fr√©quence de 0
    freq = [counts.get(d, 0) for d in dir_order]
    angles = [directions_map[d] for d in dir_order]

    fig = plt.figure(figsize=(8, 8))
    ax = fig.add_subplot(111, polar=True)
    
    # Utilise un bar plot sur un axe polaire
    ax.bar(angles, freq, width=np.pi/4, alpha=0.7, color='dodgerblue', edgecolor='k')
    
    # Configuration des labels pour les directions cardinales
    ax.set_xticks(angles)
    ax.set_xticklabels(dir_order)
    
    # Positionne les labels de rayon (fr√©quence)
    ax.set_rlabel_position(22.5)
    ax.tick_params(axis='y', labelsize=10)
    ax.set_title('Fr√©quence des Directions du Vent', pad=20, fontsize=16)
    ax.grid(True, linestyle='--', alpha=0.6)

    return _save_graph_to_base64(fig)

def generate_pressure_graph_base64(df):
    """G√©n√®re un graphique de pression sur 48h avec tendance."""
    df_pressure = df.dropna(subset=['pressure', 'time']).copy()
    
    # Filtrer les donn√©es des derni√®res 48 heures
    forty_eight_hours_ago = datetime.now() - timedelta(hours=48)
    df_pressure = df_pressure[df_pressure['time'] > forty_eight_hours_ago]

    if len(df_pressure) < 2:
        return None

    fig, ax = plt.subplots(figsize=(12, 6))
    ax.plot(df_pressure['time'], df_pressure['pressure'], marker='.', linestyle='-', label='Pression mesur√©e', color='purple')

    # Calcul et affichage de la ligne de tendance
    x_numeric = mdates.date2num(df_pressure['time'])
    z = np.polyfit(x_numeric, df_pressure['pressure'], 1)
    p = np.poly1d(z)
    ax.plot(df_pressure['time'], p(x_numeric), "r--", label='Tendance', alpha=0.8)

    ax.set_xlabel("Heure")
    ax.set_ylabel("Pression (hPa)")
    ax.set_title("Pression Atmosph√©rique (48 derni√®res heures)")
    ax.legend()
    ax.grid(True, linestyle='--', alpha=0.7)
    
    # Formatage de l'axe X
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m %Hh'))
    ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))
    plt.xticks(rotation=45, ha="right")
    fig.tight_layout()

    return _save_graph_to_base64(fig)

def generate_rain_accumulation_graph_base64(df):
    """G√©n√®re un histogramme du cumul de pluie journalier sur les 7 derniers jours."""
    df_rain = df.dropna(subset=['rain', 'time']).copy()
    df_rain.set_index('time', inplace=True)

    # Agr√©ger la pluie par jour
    daily_rain = df_rain['rain'].resample('D').sum()
    
    # Garder uniquement les 7 derniers jours
    daily_rain = daily_rain.tail(7)

    if daily_rain.empty:
        return None

    fig, ax = plt.subplots(figsize=(10, 6))
    bars = ax.bar(daily_rain.index, daily_rain.values, color='mediumseagreen')

    ax.set_xlabel("Date")
    ax.set_ylabel("Cumul de Pluie (mm)")
    ax.set_title("Cumul de Pluie Journalier (7 derniers jours)")
    ax.grid(axis='y', linestyle='--', alpha=0.7)

    # Formatage de l'axe X pour afficher "Jour/Mois"
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
    plt.xticks(rotation=0, ha="center")
    fig.tight_layout()

    return _save_graph_to_base64(fig)

def generate_stats_graph_base64(stats):
    """G√©n√®re un graphique en barres pour les temp√©ratures Min/Max (jour, semaine, mois)."""
    labels = ['Aujourd\'hui', 'Semaine', 'Mois']
    
    # On essaie de convertir les stats en float, en ignorant les 'N/A'
    try:
        mins = [float(stats['day'][0]), float(stats['week'][0]), float(stats['month'][0])]
        maxs = [float(stats['day'][1]), float(stats['week'][1]), float(stats['month'][1])]
    except (ValueError, TypeError):
        # Si une valeur est 'N/A', on ne g√©n√®re pas le graphique
        return None

    x = range(len(labels))  # positions des labels
    width = 0.35  # largeur des barres

    fig, ax = plt.subplots(figsize=(8, 5))
    rects1 = ax.bar([i - width/2 for i in x], mins, width, label='Min', color='royalblue')
    rects2 = ax.bar([i + width/2 for i in x], maxs, width, label='Max', color='crimson')

    # Ajout des labels, titre et legendes
    ax.set_ylabel('Temp√©rature (¬∞C)')
    ax.set_title('√âcarts de Temp√©rature (Min/Max)')
    ax.set_xticks(x)
    ax.set_xticklabels(labels)
    ax.legend()
    ax.grid(axis='y', linestyle='--', alpha=0.7)

    # Ajout des valeurs au-dessus des barres
    for rect in rects1 + rects2:
        height = rect.get_height()
        ax.annotate(f'{height:.1f}',
                    xy=(rect.get_x() + rect.get_width() / 2, height),
                    xytext=(0, 3),  # 3 points de d√©calage vertical
                    textcoords="offset points",
                    ha='center', va='bottom')

    fig.tight_layout()
    return _save_graph_to_base64(fig)

def get_rain_summary(df):
    """Analyse les donn√©es de pluie des derni√®res 24h et g√©n√®re un r√©sum√© textuel."""
    if df.empty:
        return "Donn√©es de pluie non disponibles."

    now = datetime.now()
    # Filtrer les donn√©es des derni√®res 24 heures
    df_24h = df[df['time'] > (now - timedelta(hours=24))].copy()
    rain_events = df_24h[df_24h['rain'] > 0]

    if rain_events.empty:
        return "Pas de pluie d√©tect√©e dans les derni√®res 24 heures."

    # Ajout d'une colonne 'date' pour pouvoir regrouper par jour
    rain_events['date'] = rain_events['time'].dt.date

    # On regroupe d'abord par jour
    daily_summaries = []
    for date, daily_group in rain_events.groupby('date'):
        
        # On identifie les √©pisodes de pluie au sein de la journ√©e
        daily_group = daily_group.copy() # Pour √©viter les avertissements pandas
        daily_group['time_diff'] = daily_group['time'].diff()
        episode_id = (daily_group['time_diff'] > timedelta(minutes=30)).cumsum()

        day_str = "Aujourd'hui" if date == now.date() else f"Hier ({date.strftime('%d/%m')})"
        
        episode_summaries = []
        for _, episode in daily_group.groupby(episode_id):
            start_time = episode['time'].min()
            end_time = episode['time'].max()
            total_rain = episode['rain'].sum()

            if len(episode) == 1:
                episode_summaries.append(f"Averse de {total_rain:.2f} mm vers {start_time.strftime('%Hh%M')}")
            else:
                duration = (end_time - start_time).total_seconds() / 60
                if duration > 5:
                    episode_summaries.append(f"{total_rain:.2f} mm entre {start_time.strftime('%Hh%M')} et {end_time.strftime('%Hh%M')}")
                else:
                    episode_summaries.append(f"{total_rain:.2f} mm autour de {start_time.strftime('%Hh%M')}")
        
        # On assemble le r√©sum√© pour la journ√©e
        if episode_summaries:
            daily_summaries.append(f"<strong>{day_str}:</strong><br>" + "<br>".join(reversed(episode_summaries)))
        else:
            daily_summaries.append(f"<strong>{day_str}:</strong> Pas de pluie enregistr√©e.")
    
    return "<br><br>".join(reversed(daily_summaries)) # On s√©pare les jours par un double saut de ligne

def get_temp_hum_summary(df):
    """Analyse la tendance de la temp√©rature et de l'humidit√© sur les 3 derni√®res heures."""
    if df.empty or len(df) < 2:
        return None

    # On ne garde que les lignes avec des donn√©es de temp√©rature et d'humidit√© valides
    df_filtered = df.dropna(subset=['temp', 'hum'])

    # On regarde les 3 derni√®res heures
    three_hours_ago = datetime.now() - timedelta(hours=3)
    recent_data = df_filtered[df_filtered['time'] > three_hours_ago].copy()

    if len(recent_data) < 2:
        return "Donn√©es r√©centes insuffisantes pour une analyse de tendance."

    # Calcul des changements
    temp_change = recent_data['temp'].iloc[-1] - recent_data['temp'].iloc[0]
    hum_change = recent_data['hum'].iloc[-1] - recent_data['hum'].iloc[0]

    # --- Analyse de la temp√©rature ---
    if temp_change > 0.8:
        temp_trend = f"en hausse ({temp_change:+.1f}¬∞C)"
    elif temp_change > 0.2:
        temp_trend = "en l√©g√®re hausse"
    elif temp_change < -0.8:
        temp_trend = f"en baisse ({temp_change:+.1f}¬∞C)"
    elif temp_change < -0.2:
        temp_trend = "en l√©g√®re baisse"
    else:
        temp_trend = "stable"

    # --- Construction de la phrase ---
    return f"Tendance sur 3h : Temp√©rature {temp_trend}."

def latlon_to_tile_coords(lat, lon, zoom):
    """Convertit des coordonn√©es GPS en coordonn√©es de tuile OpenStreetMap."""
    import math
    lat_rad = math.radians(lat)
    n = 2.0 ** zoom
    xtile = int((lon + 180.0) / 360.0 * n)
    ytile = int((1.0 - math.asinh(math.tan(lat_rad)) / math.pi) / 2.0 * n)
    return (xtile, ytile)

@login_manager.user_loader
def load_user(user_id):
    """Charge un utilisateur √† partir de son ID pour Flask-Login."""
    return users.get(user_id)

@app.route('/login', methods=['GET', 'POST'])
def login():
    """Page de connexion."""
    if current_user.is_authenticated:
        return redirect(url_for('home'))
    
    if request.method == 'POST':
        username = request.form['username']
        password = request.form['password']
        
        # On cherche l'utilisateur par son nom
        user_to_check = next((user for user in users.values() if user.username == username), None)

        if user_to_check and user_to_check.check_password(password):
            login_user(user_to_check)
            # Redirige vers la page demand√©e initialement, ou vers l'accueil
            next_page = request.args.get('next')
            return redirect(next_page or url_for('home'))
        else:
            flash('Identifiant ou mot de passe incorrect.', 'danger')

    return render_template('login.html')

# --- Fonctions utilitaires pour les couleurs dynamiques ---
def get_color_from_value(value):
    """Retourne une couleur (r,g,b) interpol√©e pour une temp√©rature donn√©e."""
    # Pivots : (Temp√©rature, R, G, B)
    # On d√©finit ici l'√©chelle de couleur : Bleu < 0, Vert ~10, Jaune ~18, Rouge > 25
    stops = [
        (-10, 52, 152, 219), # #3498db Blue (Froid)
        (0,   52, 152, 219), # #3498db Blue (Z√©ro)
        (10,  46, 204, 113), # #2ecc71 Green (Frais)
        (18,  241, 196, 15), # #f1c40f Yellow (Doux)
        (25,  231, 76, 60),  # #e74c3c Red (Chaud)
        (40,  231, 76, 60)   # #e74c3c Red (Tr√®s chaud)
    ]
    
    # Si hors limites, on prend la couleur extr√™me
    if value <= stops[0][0]: return stops[0][1:]
    if value >= stops[-1][0]: return stops[-1][1:]
    
    # Interpolation lin√©aire entre deux pivots
    for i in range(len(stops) - 1):
        t1, r1, g1, b1 = stops[i]
        t2, r2, g2, b2 = stops[i+1]
        if t1 <= value <= t2:
            ratio = (value - t1) / (t2 - t1)
            r = int(r1 + (r2 - r1) * ratio)
            g = int(g1 + (g2 - g1) * ratio)
            b = int(b1 + (b2 - b1) * ratio)
            return (r, g, b)
    return (128, 128, 128) # Gris par d√©faut

def rgb_to_hex(rgb):
    return "#{:02x}{:02x}{:02x}".format(*rgb)

def get_temp_gradient(min_t, max_t):
    """G√©n√®re un string CSS linear-gradient dynamique."""
    stops_vals = [0, 10, 18, 25] # Les temp√©ratures pivots √† inclure dans le d√©grad√©
    gradient_parts = []
    
    # Couleur de d√©but (Min)
    c_start = rgb_to_hex(get_color_from_value(min_t))
    gradient_parts.append(f"{c_start} 0%")
    
    # Ajout des pivots interm√©diaires s'ils sont dans la plage [min_t, max_t]
    range_t = max_t - min_t
    if range_t > 0.1:
        for stop in stops_vals:
            if min_t < stop < max_t:
                pct = (stop - min_t) / range_t * 100
                c_stop = rgb_to_hex(get_color_from_value(stop))
                gradient_parts.append(f"{c_stop} {pct:.1f}%")
    
    # Couleur de fin (Max)
    c_end = rgb_to_hex(get_color_from_value(max_t))
    gradient_parts.append(f"{c_end} 100%")
    
    return f"linear-gradient(90deg, {', '.join(gradient_parts)})"

@app.route("/")
@login_required
def home():
    # Initialisation des variables
    temp, hum, pressure, rain, wind, wind_dir, last_update, prediction, rain_summary, temp_hum_summary = "N/A", "N/A", "N/A", "N/A", "N/A", "", "inconnue", None, "Analyse en cours...", None
    stats = {}
    scale_min, scale_max = 100, -100 # Valeurs initiales pour d√©terminer l'√©chelle des barres

    try:
        # On lit le CSV en sp√©cifiant les 7 colonnes √©crites par le capteur
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        if not df.empty:
            # Conversion des types, en g√©rant les erreurs
            df['time'] = pd.to_datetime(df['time'], errors='coerce')
            df['pressure'] = pd.to_numeric(df['pressure'], errors='coerce')
            df['temp'] = pd.to_numeric(df['temp'], errors='coerce')
            df['hum'] = pd.to_numeric(df['hum'], errors='coerce')
            df['rain'] = pd.to_numeric(df['rain'], errors='coerce')
            df['wind_speed'] = pd.to_numeric(df['wind_speed'], errors='coerce')
            df.dropna(subset=['time'], inplace=True) # On supprime les lignes o√π la date est invalide

            last_reading = df.iloc[-1]
            temp = f"{last_reading['temp']:.1f}"  # Formatte avec une d√©cimale
            hum = f"{last_reading['hum']:.0f}"    # Formatte en entier
            wind = f"{last_reading['wind_speed']:.1f}"
            wind_dir = last_reading['wind_dir_str'] if pd.notna(last_reading['wind_dir_str']) else ""
            pressure = f"{last_reading['pressure']:.1f}" if pd.notna(last_reading['pressure']) else "N/A"
            
            # Calcul du cumul de pluie sur les derni√®res 24h
            last_24h = df[df['time'] > (datetime.now() - timedelta(hours=24))]
            rain_24h = last_24h['rain'].sum()
            rain = f"{rain_24h:.2f}"

            # --- Calcul des statistiques Min/Max ---
            now = datetime.now()
            
            periods = [
                ('day', "Aujourd'hui", now.replace(hour=0, minute=0, second=0, microsecond=0)),
                ('week', "Semaine", (now - timedelta(days=now.weekday())).replace(hour=0, minute=0, second=0, microsecond=0)),
                ('month', "Mois", now.replace(day=1, hour=0, minute=0, second=0, microsecond=0))
            ]

            for key, label, start_time in periods:
                df_period = df[df['time'] >= start_time]
                if not df_period.empty:
                    p_min = df_period['temp'].min()
                    p_max = df_period['temp'].max()
                    
                    # D√©termination de l'ic√¥ne m√©t√©o
                    rain_sum = df_period['rain'].sum()
                    press_mean = df_period['pressure'].mean()
                    if rain_sum > 0.2:
                        icon = "üåßÔ∏è"
                    elif pd.notna(press_mean) and press_mean < 1015:
                        icon = "‚òÅÔ∏è"
                    else:
                        icon = "‚òÄÔ∏è"

                    stats[key] = {
                        'label': label,
                        'min': p_min,
                        'max': p_max,
                        'min_str': f"{p_min:.1f}",
                        'max_str': f"{p_max:.1f}",
                        'icon': icon,
                        'rain_total': rain_sum,
                        'date_iso': now.strftime('%Y-%m-%d') if key == 'day' else None,
                        'gradient': get_temp_gradient(p_min, p_max)
                    }
                    # Mise √† jour de l'√©chelle globale
                    if p_min < scale_min: scale_min = p_min
                    if p_max > scale_max: scale_max = p_max

            # --- Ajout des 5 derniers jours ---
            days_fr = ["Lundi", "Mardi", "Mercredi", "Jeudi", "Vendredi", "Samedi", "Dimanche"]
            for i in range(1, 6):
                d = now - timedelta(days=i)
                start = d.replace(hour=0, minute=0, second=0, microsecond=0)
                end = d.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                df_day = df[(df['time'] >= start) & (df['time'] <= end)]
                
                if not df_day.empty:
                    p_min = df_day['temp'].min()
                    p_max = df_day['temp'].max()
                    
                    # D√©termination de l'ic√¥ne m√©t√©o
                    rain_sum = df_day['rain'].sum()
                    press_mean = df_day['pressure'].mean()
                    if rain_sum > 0.2:
                        icon = "üåßÔ∏è"
                    elif pd.notna(press_mean) and press_mean < 1015:
                        icon = "‚òÅÔ∏è"
                    else:
                        icon = "‚òÄÔ∏è"

                    stats[f'day_{i}'] = {
                        'label': days_fr[d.weekday()],
                        'min': p_min,
                        'max': p_max,
                        'min_str': f"{p_min:.1f}",
                        'max_str': f"{p_max:.1f}",
                        'icon': icon,
                        'rain_total': rain_sum,
                        'date_iso': d.strftime('%Y-%m-%d'),
                        'gradient': get_temp_gradient(p_min, p_max)
                    }
                    if p_min < scale_min: scale_min = p_min
                    if p_max > scale_max: scale_max = p_max

            # Ajout d'une petite marge pour l'affichage graphique
            if scale_min != 100: scale_min -= 2
            if scale_max != -100: scale_max += 2
            
            # G√©n√©ration de la pr√©diction (uniquement si des donn√©es de pression existent)
            prediction = get_weather_prediction(df)

            last_update = last_reading['time'].strftime("%d/%m/%Y √† %H:%M:%S")

    except (FileNotFoundError, pd.errors.EmptyDataError):
        # Le fichier n'existe pas encore ou est vide
        pass
    
    # On d√©place les appels aux fonctions d'analyse ici pour plus de clart√©
    rain_summary = get_rain_summary(df) if 'df' in locals() and not df.empty else "Donn√©es non disponibles."
    temp_hum_summary = get_temp_hum_summary(df) if 'df' in locals() and not df.empty else None
    
    return render_template("home.html", temp=temp, hum=hum, pressure=pressure, rain=rain, wind=wind, wind_dir=wind_dir, last_update=last_update, prediction=prediction, stats=stats, scale_min=scale_min, scale_max=scale_max, rain_summary=rain_summary, temp_hum_summary=temp_hum_summary)

@app.route("/pluviometer_logs")
@login_required
def pluviometer_logs_page():
    """Affiche les logs en direct du pluviom√®tre."""
    logs_content = "Aucun basculement enregistr√© pour le moment."
    total_tips = 0
    total_rain = 0.0
    try:
        with open(PLUVIOMETER_EVENT_LOG, "r") as f:
            lines = f.readlines()
            if lines:
                logs_content = "".join(lines)
                total_tips = len(lines)
                total_rain = total_tips * MM_PER_TIP
    except FileNotFoundError:
        pass # Le fichier n'existe pas encore
    return render_template("pluviometer_logs.html", 
                           logs_content=logs_content, 
                           total_tips=total_tips, 
                           total_rain=f"{total_rain:.2f}")

@app.route("/admin/clear_data", methods=['POST'])
@login_required
def admin_clear_data():
    """Efface les fichiers de donn√©es (CSV principal et logs du pluviom√®tre)."""
    try:
        # Supprime le fichier de donn√©es principal. Le script capteur le recr√©era.
        if os.path.exists(CSV_FILE):
            os.remove(CSV_FILE)
        
        # Supprime √©galement le fichier de log des basculements pour la coh√©rence.
        if os.path.exists(PLUVIOMETER_EVENT_LOG):
            os.remove(PLUVIOMETER_EVENT_LOG)
            
    except Exception as e:
        print(f"Erreur lors de l'effacement des fichiers de donn√©es : {e}")
    
    flash("Toutes les donn√©es ont √©t√© effac√©es.", "success")
    return redirect(url_for('admin_page'))

@app.route("/admin/clear_pluviometer_logs", methods=['POST'])
@login_required
def admin_clear_pluviometer_logs():
    """Efface le contenu du fichier de log du pluviom√®tre."""
    try:
        with open(PLUVIOMETER_EVENT_LOG, "w") as f:
            # Le simple fait d'ouvrir en mode 'w' efface le fichier.
            pass
    except Exception as e:
        print(f"Erreur lors de l'effacement du fichier de log : {e}")
    
    flash("Les logs du pluviom√®tre ont √©t√© effac√©s.", "success")
    return redirect(url_for('pluviometer_logs_page'))

@app.route('/history')
@login_required
def history():
    """Affiche l'historique complet des donn√©es avec pagination et filtrage par date."""
    try:
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        df.dropna(subset=['time'], inplace=True) # On s'assure que la colonne 'time' n'est pas vide
        df['time'] = pd.to_datetime(df['time'], errors='coerce')
        df.dropna(subset=['time'], inplace=True) # On supprime les lignes o√π la conversion de date a √©chou√©

        # --- Logique de filtrage par date ---
        start_date_str = request.args.get('start_date', '')
        end_date_str = request.args.get('end_date', '')
        
        if start_date_str:
            start_date = datetime.strptime(start_date_str, '%Y-%m-%d')
            df = df[df['time'] >= start_date]
        
        if end_date_str:
            # On ajoute un jour et on compare √† "inf√©rieur √†" pour inclure toute la journ√©e de la date de fin.
            end_date = datetime.strptime(end_date_str, '%Y-%m-%d') + timedelta(days=1)
            df = df[df['time'] < end_date]

        # On inverse le DataFrame pour avoir les donn√©es les plus r√©centes en premier
        df = df.iloc[::-1]

        # Logique de pagination
        page = request.args.get('page', 1, type=int)
        per_page = 50  # 50 entr√©es par page
        total_rows = len(df) 
        total_pages = (total_rows + per_page - 1) // per_page

        start = (page - 1) * per_page
        end = start + per_page
        df_page = df.iloc[start:end].copy() # .copy() pour √©viter un avertissement

        # Formater pour l'affichage
        df_page['time'] = pd.to_datetime(df_page['time']).dt.strftime('%d/%m/%Y %H:%M')
        df_page = df_page.rename(columns={'time': 'Date/Heure', 'temp': 'Temp (¬∞C)', 'hum': 'Humidit√© (%)', 'pressure': 'Pression (hPa)', 'rain': 'Pluie (mm)', 'wind_speed': 'Vent (km/h)', 'wind_dir_str': 'Direction'})
        table_html = df_page.to_html(classes='data-table', index=False, justify='center')

    except (FileNotFoundError, pd.errors.EmptyDataError):
        table_html = "<p>Aucune donn√©e d'historique √† afficher.</p>"
        page, total_pages, start_date_str, end_date_str = 1, 1, '', ''

    return render_template('history.html', table_html=table_html, current_page=page, total_pages=total_pages, start_date=start_date_str, end_date=end_date_str)

@app.route('/logout')
@login_required
def logout():
    logout_user()
    return redirect(url_for('login'))

@app.route('/admin')
@login_required
def admin_page():
    """Page d'administration pour les actions sensibles."""
    return render_template('admin.html', config=config)

@app.route('/admin/update_config', methods=['POST'])
@login_required
def admin_update_config():
    """Met √† jour le fichier de configuration."""
    try:
        new_config = {
            "owm_api_key": request.form['owm_api_key'],
            "latitude": float(request.form['latitude']),
            "longitude": float(request.form['longitude'])
        }
        save_config(new_config)
        flash("Configuration mise √† jour avec succ√®s ! L'application va red√©marrer pour appliquer les changements.", "success")
        # On recharge la configuration pour la session en cours
        global config, LATITUDE, LONGITUDE, OWM_API_KEY
        config = new_config
        LATITUDE, LONGITUDE, OWM_API_KEY = config['latitude'], config['longitude'], config['owm_api_key']
    except ValueError:
        flash("Erreur : La latitude et la longitude doivent √™tre des nombres.", "danger")
    except Exception as e:
        flash(f"Une erreur est survenue : {e}", "danger")
    return redirect(url_for('admin_page'))

@app.route('/admin/change_password', methods=['POST'])
@login_required
def admin_change_password():
    """Change le mot de passe de l'administrateur."""
    current_password = request.form.get('current_password')
    new_password = request.form.get('new_password')
    confirm_password = request.form.get('confirm_password')

    # V√©rification du mot de passe actuel
    if not current_user.check_password(current_password):
        flash("Le mot de passe actuel est incorrect.", "danger")
        return redirect(url_for('admin_page'))

    if new_password != confirm_password:
        flash("Les nouveaux mots de passe ne correspondent pas.", "danger")
        return redirect(url_for('admin_page'))

    # Mise √† jour du hash
    new_hash = generate_password_hash(new_password)
    
    # Mise √† jour en m√©moire et dans la config
    users[current_user.id].password_hash = new_hash
    config['admin_password_hash'] = new_hash
    save_config(config)

    flash("Mot de passe modifi√© avec succ√®s.", "success")
    return redirect(url_for('admin_page'))

@app.route("/download")
@login_required
def download():
    return send_file(CSV_FILE, as_attachment=True)

@app.route("/hourly_graph")
@login_required
def hourly_graph():
    graph_html = None
    try:
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        if not df.empty:
            df['time'] = pd.to_datetime(df['time'])
            df['temp'] = pd.to_numeric(df['temp'], errors='coerce')
            graph_html = generate_hourly_graph_base64(df)
    except (FileNotFoundError, pd.errors.EmptyDataError):
        pass
    return render_template("hourly_graph.html", graph_html=graph_html)

@app.route("/daily_graph")
@login_required
def daily_graph():
    """Affiche le graphique d√©taill√© pour une journ√©e sp√©cifique."""
    date_str = request.args.get('date')
    if not date_str:
        return redirect(url_for('home'))
        
    graph_html = None
    title = f"M√©t√©o du {date_str}"
    
    try:
        target_date = datetime.strptime(date_str, '%Y-%m-%d')
        start_day = target_date.replace(hour=0, minute=0, second=0)
        end_day = target_date.replace(hour=23, minute=59, second=59)
        
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        if not df.empty:
            df['time'] = pd.to_datetime(df['time'], errors='coerce')
            df['temp'] = pd.to_numeric(df['temp'], errors='coerce')
            df['hum'] = pd.to_numeric(df['hum'], errors='coerce')
            df['rain'] = pd.to_numeric(df['rain'], errors='coerce')
            
            df_day = df[(df['time'] >= start_day) & (df['time'] <= end_day)]
            if not df_day.empty:
                graph_html = generate_hourly_graph_base64(df_day, filter_recent=False, title=f"Donn√©es horaires du {date_str}")
    except (ValueError, FileNotFoundError, pd.errors.EmptyDataError):
        pass
        
    return render_template("graph_page.html", title=title, graph_html=graph_html)

@app.route("/wind_rose")
@login_required
def wind_rose():
    """Affiche la rose des vents."""
    graph_html = None
    try:
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        if not df.empty:
            graph_html = generate_wind_rose_base64(df)
    except (FileNotFoundError, pd.errors.EmptyDataError):
        pass
    return render_template("graph_page.html", title="Rose des Vents", graph_html=graph_html)

@app.route("/pressure_graph")
@login_required
def pressure_graph():
    """Affiche le graphique de pression."""
    graph_html = None
    try:
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        if not df.empty:
            df['time'] = pd.to_datetime(df['time'], errors='coerce')
            df['pressure'] = pd.to_numeric(df['pressure'], errors='coerce')
            graph_html = generate_pressure_graph_base64(df)
    except (FileNotFoundError, pd.errors.EmptyDataError):
        pass
    return render_template("graph_page.html", title="Graphique de Pression", graph_html=graph_html)

@app.route("/rain_graph")
@login_required
def rain_graph():
    """Affiche le graphique du cumul de pluie."""
    graph_html = None
    try:
        df = pd.read_csv(CSV_FILE, header=0, names=["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"], on_bad_lines='skip')
        if not df.empty:
            df['time'] = pd.to_datetime(df['time'], errors='coerce')
            df['rain'] = pd.to_numeric(df['rain'], errors='coerce')
            graph_html = generate_rain_accumulation_graph_base64(df)
    except (FileNotFoundError, pd.errors.EmptyDataError):
        pass
    return render_template("graph_page.html", title="Cumul de Pluie Journalier", graph_html=graph_html)

@app.route("/satellite")
@login_required
def satellite_page():
    """Affiche l'image satellite."""
    archive_dir = "static/satellite_archive"
    image_files = []
    if os.path.exists(archive_dir):
        # On trie les images pour les avoir dans l'ordre chronologique
        files = sorted(os.listdir(archive_dir))
        image_files = [os.path.join(archive_dir, f) for f in files]

    return render_template("satellite.html", image_files=image_files)


def _save_graph_to_base64(fig):
    img = io.BytesIO()
    fig.savefig(img, format="png")
    plt.close(fig)
    img.seek(0)
    graph_url = base64.b64encode(img.getvalue()).decode('utf8')
    return f"data:image/png;base64,{graph_url}"

def get_last_csv_line(filepath):
    """
    Lit efficacement la derni√®re ligne non vide d'un fichier.
    C'est beaucoup plus performant que de lire tout le fichier avec Pandas.
    """
    try:
        with open(filepath, 'rb') as f:
            # On va √† la fin du fichier, moins un peu pour trouver la derni√®re ligne
            f.seek(-2, os.SEEK_END)
            while f.read(1) != b'\n':
                f.seek(-2, os.SEEK_CUR)
            # La derni√®re ligne compl√®te est apr√®s le '\n' que nous avons trouv√©
            last_line = f.readline().decode('utf-8')
            return last_line.strip().split(',')
    except (IOError, IndexError):
        # Fichier trop petit, vide ou inexistant
        return None

@app.route("/api/v1/sensors")
def api_sensors():
    """Fournit les derni√®res donn√©es des capteurs au format JSON pour Home Assistant."""
    try:
        last_reading_list = get_last_csv_line(CSV_FILE)

        # On v√©rifie qu'on a bien nos 7 colonnes
        if not last_reading_list or len(last_reading_list) < 7:
            return jsonify({"error": "No data available"}), 404

        # On recr√©e un dictionnaire avec les noms des colonnes pour plus de clart√©
        headers = ["time", "temp", "hum", "pressure", "rain", "wind_speed", "wind_dir_str"]
        last_reading = dict(zip(headers, last_reading_list))

        # Conversion des valeurs en types corrects (float, int)
        temp = float(last_reading['temp'])
        hum = float(last_reading['hum'])
        rain = float(last_reading['rain'])
        wind_speed = float(last_reading['wind_speed'])
        wind_dir = last_reading.get('wind_dir_str', 'N/A') # On r√©cup√®re la direction du vent
        
        # La pression peut √™tre une cha√Æne vide si le BME280 n'est pas l√†
        try:
            pressure = float(last_reading['pressure'])
        except (ValueError, KeyError):
            pressure = None

        data = {
            "temperature": round(temp, 1),
            "humidity": round(hum, 1),
            "rain": round(rain, 4),
            "pressure": round(pressure, 1) if pressure is not None else None,
            "wind_speed": round(wind_speed, 1),
            "wind_direction": wind_dir,
            # On convertit la date string en objet datetime puis en format ISO
            "last_update": datetime.strptime(last_reading['time'], "%Y-%m-%d %H:%M:%S").isoformat()
        }
        return jsonify(data)

    except (FileNotFoundError, pd.errors.EmptyDataError):
        return jsonify({"error": "Data source not found or empty"}), 404

@app.route('/favicon.ico')
def favicon():
    """Route pour servir le logo comme favicon (ic√¥ne de l'onglet)."""
    return send_file(os.path.join(app.root_path, 'static', 'img', 'meteopi.png'), mimetype='image/png')


if __name__ == "__main__":
    # Le nettoyage est maintenant fait au-dessus.
    app.run(host="0.0.0.0", port=5000)
